# react-native-sherpa-onnx-offline-tts

A lightweight ReactÂ Native wrapper around [Sherpaâ€‘ONNX](https://github.com/k2-fsa/sherpa-onnx) that lets you run **100â€¯% offline Textâ€‘toâ€‘Speech** on iOS and Android.

---

## âœ¨ Features

| | |
|---|---|
| ğŸ”Š **Offline** â€“ all synthesis happens onâ€‘device, no network needed | âš¡ **Fast** â€“ realâ€‘time (or faster) generation on modern phones |
| ğŸ™ï¸ **Natural voices** â€“ dropâ€‘in support for Piper / VITS ONNX models | ğŸ› ï¸ **Simple API** â€“ a handful of async methods you already know |

---

## ğŸ“¦ Installation

```bash
# Add the library
npm install react-native-sherpa-onnx-offline-tts
# or
yarn add react-native-sherpa-onnx-offline-tts

# iOS only\	npx pod-install
```

> **Minimumâ€¯versions**  |  AndroidÂ 5.0 (APIÂ 21) â€¢ iOSÂ 11

---

## ğŸš€ Quick Start

1. **Choose a model** â€“ grab any [Piper](https://github.com/k2-fsa/sherpa-onnx/releases/download/tts-models/vits-piper-en_US-ryan-medium.tar.bz2) voice ZIP (e.g. `vits-piper-en_US-ryan-medium.zip`) and host it yourself or bundle it with the app.
2. **Download & unzip** the archive into your appâ€™s sandbox (the example below uses **reactâ€‘nativeâ€‘fs** & **reactâ€‘nativeâ€‘zipâ€‘archive**).
3. **Create a config JSON** with absolute paths to `*.onnx`, `tokens.txt`, and the `espeak-ng-data` folder.
4. **Initialize**, then generate or stream speech.

```tsx
import TTSManager from 'react-native-sherpa-onnx-offline-tts';
import RNFS from 'react-native-fs';
import { unzip } from 'react-native-zip-archive';

const MODEL_URL =
  'https://example.com/vits-piper-en_US-ryan-medium.zip';

async function setupTTS() {
  const archive = `${RNFS.DocumentDirectoryPath}/vits.zip`;
  const extractRoot = `${RNFS.DocumentDirectoryPath}/extracted`;

  // 1ï¸âƒ£  Download if missing
  if (!(await RNFS.exists(archive))) {
    await RNFS.downloadFile({ fromUrl: MODEL_URL, toFile: archive }).promise;
  }

  // 2ï¸âƒ£  Unpack if first run
  if (!(await RNFS.exists(`${extractRoot}/vits-piper-en_US-ryan-medium`))) {
    await unzip(archive, extractRoot);
  }

  // 3ï¸âƒ£  Point the engine to the files
  const base = `${extractRoot}/vits-piper-en_US-ryan-medium`;
  const cfg = {
    modelPath: `${base}/en_US-ryan-medium.onnx`,
    tokensPath: `${base}/tokens.txt`,
    dataDirPath: `${base}/espeak-ng-data`,
  };

  // 4ï¸âƒ£  Initialise (only once per session)
  await TTSManager.initialize(JSON.stringify(cfg));
}

async function sayHello() {
  const text = 'HelloÂ world â€“ spoken entirely offline!';
  const speakerId = 0;   // Piper uses 0 for singleâ€‘speaker models
  const speed = 1.0;     // 1Â == default, <Â 1 slower, >Â 1 faster

  await TTSManager.generateAndPlay(text, speakerId, speed);
}
```

---

## ğŸ“š API Reference

| Method | Signature | Description |
|--------|-----------|-------------|
| **initialize** | `(modelConfigJson: string): Promise<void>` | Must be called once before any synthesis. Pass a JSON string with `modelPath`, `tokensPath`, `dataDirPath`. |
| **generate** | `(text: string, speakerId: number, speed: number): Promise<{success: boolean, totalChunks: number}>` | Generates speech and emits chunks progressively via `AudioChunkGenerated` event. Returns a promise that resolves when all chunks are generated. |
| **generateAndPlay** | `(text: string, speakerId: number, speed: number): Promise<void>` | Generates speech and streams it to the device speaker. |
| **stopPlaying** | `(): void` | Immediately stops playback. |
| **addVolumeListener** | `(cb: (volume: number) => void): EmitterSubscription` | Subscribes to realâ€‘time RMS volume callbacks during playback. Call `subscription.remove()` to unsubscribe. |
| **addAudioChunkListener** | `(cb: (data: {chunk: string, index: number, total: number, sampleRate: number}) => void): EmitterSubscription` | Subscribes to audio chunk events during `generate()`. The `chunk` is base64-encoded Float32 PCM data. Call `subscription.remove()` to unsubscribe. |
| **deinitialize** | `(): void` | Frees native resources â€“ call this when your app unmounts or goes to background for a long time. |

---

## ğŸ”Š Supported Models

* Any **Piper** VITS model (`*.onnx`) with matching `tokens.txt` and `espeak-ng-data` directory.
* Multiâ€‘speaker models are supported â€“ just pass the desired `speakerId`.

> Need other formats? Feel free to open an issue or pull request.

---

## ğŸ› ï¸ Example App

A minimal, productionâ€‘ready example (downloads the model on first launch, shows a progress spinner, animates to mic volume, etc.) lives in **`example/App.tsx`** â€“ the snippet below is an abridged version:

```tsx title="example/App.tsx"
const App = () => {
  /* full source lives in the repo */
  return (
    <View style={styles.container}>
      {isDownloading ? (
        <ProgressBar progress={downloadProgress} />
      ) : (
        <>
          <AnimatedCircle scale={volume} />
          <Button title="Play" onPress={handlePlay} disabled={isPlaying} />
          <Button title="Stop" onPress={handleStop} disabled={!isPlaying} />
        </>
      )}
    </View>
  );
};
```

---

## ğŸ¤ Contributing

Bug reports and PRs are welcome!  Please see [CONTRIBUTING.md](CONTRIBUTING.md) for the full development workflow.

---

## ğŸ“„ License

[MIT](LICENSE)

---

Made with â¤ï¸ &Â [createâ€‘reactâ€‘nativeâ€‘library](https://github.com/callstack/react-native-builder-bob)

